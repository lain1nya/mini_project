from fastapi import FastAPI
from nagging_graph import llm, embeddings, supervisor_executor
from models import RemarkRequest, FeedbackRequest, PriceSuggestionRequest, PriceAnalysisOutput
from openai import AzureOpenAI
from pprint import pprint
from db import add_remarks_to_faiss
from langchain_community.vectorstores import FAISS
from datetime import datetime
from fastapi.middleware.cors import CORSMiddleware
from langchain_openai import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from langchain_community.embeddings import AzureOpenAIEmbeddings
from langchain.output_parsers import ResponseSchema, PydanticOutputParser
from pydantic import BaseModel, Field

output_parser = PydanticOutputParser(pydantic_object=PriceAnalysisOutput)

# FastAPI ì•± ìƒì„±
app = FastAPI()

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì†Œë“œ í—ˆìš©
    allow_headers=["*"],  # ëª¨ë“  HTTP í—¤ë” í—ˆìš©
)

# í”¼ë“œë°±ì„ ì ìš©í•  ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
remark_store = {}

def get_ai_response(prompt_messages):
    # í•´ì„: ë°ì´í„°ê°€ íë¥´ëŠ” ìˆœì„œ
    # í”„ë¡¬í”„íŠ¸ -> LLM ì‘ë‹µ -> ì‘ë‹µ íŒŒì‹±
    chain = prompt_messages | llm | output_parser
    
    print(f"prompt_messages: {prompt_messages}")
    try:
        # invoke ë©”ì„œë“œ ì‚¬ìš©
        parsed_response = chain.invoke({}) # í”„ë¡¬í¬íŠ¸ì— ì´ë¯¸ ëª¨ë“  ê°’ì´ í¬í•¨ë˜ì–´ ìˆìŒ
        # PriceAnalysisOutput ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ê²€ì¦
        analysis_output = PriceAnalysisOutput(
            thinking_steps=parsed_response["thinking_steps"],
            analysis=parsed_response["analysis"],
            final_explanation=parsed_response["final_explanation"],
            price=parsed_response["price"]
        )
        return analysis_output.final_explanation, f"{analysis_output.price}ë§Œì›"
    except Exception as e:
        print(f"âš ï¸ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return "AI ì‘ë‹µì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "ê°€ê²©ì„ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

def generate_price_suggestion_prompt(base_explanation: str, positive_count: int, negative_count: int, original_price: int, suggested_price: int, reason: str) -> ChatPromptTemplate:
    # ì„¤ëª… ìƒì„±ì„ ìœ„í•œ ì¶œë ¥ íŒŒì„œ ìŠ¤í‚¤ë§ˆ
    class ExplanationResponse(BaseModel):
        explanation: str = Field(description="ì”ì†Œë¦¬ì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¤ëª…")
        price: int = Field(description="í”¼ë“œë°±ì„ ë°˜ì˜í•œ ê°€ê²©")

    explanation_parser = PydanticOutputParser(pydantic_object=ExplanationResponse)
    
    template = """
    ë‹¤ìŒì€ ì”ì†Œë¦¬ì— ëŒ€í•œ ê¸°ë³¸ ì„¤ëª…ì…ë‹ˆë‹¤:
    "{base_explanation}"

    ì´ ì”ì†Œë¦¬ì— ëŒ€í•œ í”¼ë“œë°± í˜„í™©:
    - ê¸ì •ì  í‰ê°€: {positive_count}íšŒ
    - ë¶€ì •ì  í‰ê°€: {negative_count}íšŒ

    í˜„ì¬ ìƒí™©:
    - ê¸°ì¡´ ê°€ê²©: {original_price}ë§Œì›
    - ì œì•ˆëœ ê°€ê²©: {suggested_price}ë§Œì›
    - ê°€ê²© ì œì•ˆ ì´ìœ : {reason}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì”ì†Œë¦¬ì— ëŒ€í•œ ìƒˆë¡œìš´ ì„¤ëª…ê³¼ ê°€ê²©ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
    ì„¤ëª…ì˜ ê²½ìš° ê¸°ë³¸ ì„¤ëª…ì˜ ë³¸ì§ˆì€ ìœ ì§€í•˜ë©´ì„œ, ì‚¬ìš©ìë“¤ì˜ í”¼ë“œë°±ì„ ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì˜í•´ì£¼ì„¸ìš”.
    ê°€ê²© ì œì•ˆê³¼ ë¹„ìš©ì— ëŒ€í•œ ì´ìœ ëŠ” ì„¤ëª…ì— í¬í•¨í•˜ì§€ ì•Šê³ , ì„¤ëª…ì€ í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ê°€ê²©ì˜ ê²½ìš° ê¸ì •ì  í‰ê°€ì˜ íšŸìˆ˜ì™€ ë¶€ì •ì  í‰ê°€ì˜ íšŸìˆ˜, ê¸°ì¡´ ê°€ê²©ê³¼, ì œì•ˆëœ ê°€ê²©ê³¼ ì´ìœ ë¥¼ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì ì •í•œ ê°€ê²©ì„ ì±…ì •í•´ì£¼ì„¸ìš”.
    ê°€ê²©ì˜ ìˆ«ìëŠ” 1 ~ 15 ì‚¬ì´ë¡œë§Œ ë¦¬í„´í•´ì£¼ì„¸ìš”.

    {format_instructions}
    """

    # ê¸°ì¡´ì— explanation ì—…ë°ì´íŠ¸ í•œ ê²ƒì„ langgraphì— ì¶”ê°€
    # check point, human in the loop
    # ë³„ë„ì˜ ê·¸ë˜í”„
    # ì‹«ì–´ìš” ë°°ì¹˜

    # langchain_community.vectorstores

    prompt = ChatPromptTemplate.from_template(
        template=template,
        partial_variables={"format_instructions" : explanation_parser.get_format_instructions()}
    )

    # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìì²´ë¥¼ ë°˜í™˜
    return prompt, explanation_parser

def get_updated_explanation(prompt_template: ChatPromptTemplate, explanation_parser: PydanticOutputParser, **kwargs) -> str:

    # ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ ì²´ì¸ êµ¬ì„±
    chain = prompt_template | llm | explanation_parser
    
    try:
        # invoke ë©”ì„œë“œ ì‚¬ìš© (ì…ë ¥ ê°’ ì—†ì´)
        parsed_response = chain.invoke(kwargs)
        print(f"AIì‘ë‹µ: {parsed_response}")
        return parsed_response.explanation, parsed_response.price
    except Exception as e:
        print(f"âš ï¸ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

# DONE
@app.post("/get_price/")
async def get_price(request: RemarkRequest):
    print(f"ì…ë ¥ëœ ì”ì†Œë¦¬: {request.remark}")
    state = {
        "remark": request.remark,
        "category": "",
        "suggested_price": 0,
        "explanation": "",
    }
     
    result = supervisor_executor.invoke(state)

    remark_store[request.remark] = result

    return {
        "result" : result,
        "message" : "ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ê°€ê²©ì´ ì–´ë–¤ì§€ ì•Œë ¤ì£¼ì„¸ìš”."
    }

@app.post("/feedback/")
async def handle_feedback(request: FeedbackRequest):
    """ì¢‹ì•„ìš” vs ë‚˜ë¹ ìš” í”¼ë“œë°± ë°˜ì˜"""
    
    if remark_store == {}:
        return {
            "status" : "error",
            "message" : "í•´ë‹¹ ì”ì†Œë¦¬ì— ëŒ€í•œ ë¶„ì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        }
    
    remark_data = remark_store[request.remark]

    if request.is_positive:
        remark_data["positive_feedback"] += 1
    else: 
        remark_data["negative_feedback"] += 1

    remark_store[request.remark] = remark_data

    
    return {
        "status": "success",
        "message": "í”¼ë“œë°±ì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
    }

@app.post("/suggest-price/")
async def suggest_price(request: PriceSuggestionRequest):
    print(f"ê°€ê²© ì œì•ˆ ë°›ìŒ: {request}")
    
    # ê¸°ì¡´ ë°ì´í„° ê²€ìƒ‰
    similar_results = process_remark_with_tool_calling(request.remark, top_k=1)
    if not similar_results:
        return {"status": "error", "message": "ê°€ê²©ì„ ì œì•ˆí•  ì”ì†Œë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    result = similar_results[0]
    metadata = result["metadata"]
    
    # ê¸°ì¡´ í”¼ë“œë°± ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    feedback_count = metadata.get("feedback_count", 0)
    positive_feedback = metadata.get("positive_feedback", 0)
    negative_feedback = metadata.get("negative_feedback", 0)
    feedback_history = metadata.get("feedback_history", [])
    
    # ê°€ê²© ì œì•ˆ ë° ì´ìœ  ì¶”ê°€ ë°˜ì˜
    feedback_history.append({
        "is_positive": False,
        "suggested_price": request.suggested_price,
        "reason": request.reason if request.reason else "ì´ìœ  ì—†ìŒ",
        "timestamp": datetime.now().isoformat()
    })

    print(f"ì œì•ˆ ê°€ê²©: {request.suggested_price}")
    
    # ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ê°€ê²© ê³„ì‚°
    weight_existing = positive_feedback / (positive_feedback + negative_feedback)
    weight_new = negative_feedback / (positive_feedback + negative_feedback)
    final_price = int(metadata["price"] * weight_existing + request.suggested_price * weight_new)
    
    # ê¸°ì¡´ ì„¤ëª…ì—ì„œ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
    base_explanation = metadata['explanation'].split('ğŸ“– ì„¤ëª…: ')[0].split('.')[0].strip()
    print(f"ìµœì¢… ê°€ê²©: {final_price}")
    
    # AIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ ì„¤ëª… ìƒì„±
    prompt_template, explanation_parser = generate_price_suggestion_prompt(
        base_explanation,
        positive_feedback,
        negative_feedback,
        metadata["price"], 
        request.suggested_price,
        request.reason if request.reason else "ì´ìœ  ì—†ìŒ"
    )

    new_explanation, new_price = get_updated_explanation(
        prompt_template,
        explanation_parser,
        base_explanation=base_explanation,
        positive_count=positive_feedback,
        negative_count=negative_feedback,
        original_price=metadata["price"],
        suggested_price=request.suggested_price,
        reason=request.reason if request.reason else "ì´ìœ  ì—†ìŒ"
    )

    print(f"ì œì•ˆëœ ê°€ê²©: {request.suggested_price}")

    if not new_explanation:
        new_explanation = f"{base_explanation}"
    
    # ì—…ë°ì´íŠ¸ëœ ë°ì´í„°ë¡œ ìƒˆ ë²¡í„° ìƒì„± ë° ì €ì¥
    new_remarks = [{
        "remark": request.remark,
        "explanation": new_explanation,
        "price": new_price,
        "feedback_count": feedback_count,
        "positive_feedback": positive_feedback,
        "negative_feedback": negative_feedback,
        "feedback_history": feedback_history,
        "last_updated": datetime.now().isoformat()
    }]

    print(f"ìƒˆë¡œìš´ ì„¤ëª… {new_explanation}")
    
    try:
        add_remarks_to_faiss(new_remarks, update_existing=True)
        print("ê°€ê²© ì œì•ˆì´ ë°ì´í„°ë² ì´ìŠ¤ì— ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return {
            "status": "success", 
            "message": "ê°€ê²© ì œì•ˆì´ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "updated_price": f"{new_price}ë§Œì›"
        }
    except Exception as e:
        print(f"ê°€ê²© ì œì•ˆ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {"status": "error", "message": "ê°€ê²© ì œì•ˆ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}