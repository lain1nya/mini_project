import os
import json
import pprint
from langchain_community.vectorstores import FAISS
from langchain_openai import AzureOpenAIEmbeddings
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# FAISS ì¸ë±ìŠ¤ & ë©”íƒ€ë°ì´í„° íŒŒì¼ ê²½ë¡œ
index_path = "faiss_index"
metadata_path = "remark_metadata.json"

# Azure OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embeddings = AzureOpenAIEmbeddings(
    azure_deployment=os.getenv("AOAI_DEPLOY_EMBED_3_LARGE"),
    openai_api_version="2024-10-21",
    azure_endpoint=os.getenv("AOAI_ENDPOINT"),
    api_key=os.getenv("AOAI_API_KEY")
)

# ê¸€ë¡œë²Œ db ê°ì²´
db = None

# FAISS ì¸ë±ìŠ¤ ë¡œë“œ ë˜ëŠ” ìƒì„±
def load_faiss_index():
    """FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±"""
    global db
    if os.path.exists(index_path):
        try:
            db = FAISS.load_local(index_path, embeddings, allow_dangerous_deserialization=True)
            print("âœ… ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì„±ê³µ")
        except Exception as e:
            print(f"âš ï¸ FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸš€ ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ ìƒì„±")
            db = FAISS.from_texts(["ì„ì‹œ ë°ì´í„°ì…ë‹ˆë‹¤."], embeddings)  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
            db.save_local(index_path)
    else:
        print("ğŸš€ FAISS ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œìš´ ì¸ë±ìŠ¤ ìƒì„±")
        db = FAISS.from_texts(["ì„ì‹œ ë°ì´í„°ì…ë‹ˆë‹¤."], embeddings)  # ê¸°ë³¸ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
        db.save_local(index_path)

# FAISS ë©”íƒ€ë°ì´í„° ë¡œë“œ
def load_metadata():
    """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
    if os.path.exists(metadata_path):
        with open(metadata_path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

# ë©”íƒ€ë°ì´í„° ì €ì¥
def save_metadata(metadata):
    """ë©”íƒ€ë°ì´í„° ì €ì¥"""
    with open(metadata_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=4)

# FAISS ë°ì´í„° ì¶”ê°€ í•¨ìˆ˜
def add_remarks_to_faiss(remarks):
    """FAISS ë²¡í„°DBì— ë°ì´í„° ì¶”ê°€"""
    global db
    metadata = load_metadata()

    # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    metadata.extend(remarks)

    texts = [f"{remark['remark']} (tone: {remark['tone']})" for remark in remarks]
    
    metadata_list = [
        {
            "remark": remark["remark"],
            "updated_remark": remark["updated_remark"],
            "tone" : remark["tone"],
            "category": remark["category"],
            "explanation": remark["explanation"],
            "suggested_price": remark["suggested_price"],
            "repetition": remark["repetition"],
            "mental_damage": remark["mental_damage"],
            "avoidance_difficulty": remark["avoidance_difficulty"],
            "replaceability": remark["replaceability"],
            "positive_feedback": remark.get("positive_feedback", 0),
            "negative_feedback": remark.get("negative_feedback", 0)
        }
        for remark in remarks
    ]

    # âœ… FAISS ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ë²¡í„° ì¶”ê°€)
    db.add_texts(texts=texts, metadatas=metadata_list)
    db.save_local(index_path)

    # ë©”íƒ€ë°ì´í„° ì €ì¥
    save_metadata(metadata)
    print(f"âœ… {len(remarks)}ê°œì˜ remarkê°€ FAISSì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")

# FAISSì—ì„œ ìœ ì‚¬í•œ ì”ì†Œë¦¬ ê²€ìƒ‰
def search_similar_remark(query: str, tone: str, category: str, top_k: int=1):
    if db is None:
        print("âŒ FAISS DBê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return None

    # ê²€ìƒ‰ ìˆ˜í–‰
    query_with_tone = f"{query} (tone: {tone})"
    docs = db.similarity_search(query_with_tone, top_k)

    if not docs:
        print("âŒ ìœ ì‚¬í•œ ì”ì†Œë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    filtered_docs = [doc for doc in docs if doc.metadata and doc.metadata.get("category") == category]

    if not filtered_docs:
        print(f"âš ï¸ ê°™ì€ ì¹´í…Œê³ ë¦¬({category})ì—ì„œ ìœ ì‚¬í•œ ì”ì†Œë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    most_similar_doc = filtered_docs[0]  # ğŸ”¥ ì²« ë²ˆì§¸ ê²°ê³¼ ì„ íƒ
    return most_similar_doc

# ğŸ”¥ FAISSì—ì„œ ëª¨ë“  remark ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
def fetch_all_remarks_from_faiss():
    """FAISSì—ì„œ ëª¨ë“  remark ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    if db is None:
        print("âŒ FAISS DBê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return []

    # ğŸ” FAISSì—ì„œ ëª¨ë“  ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_docs = db.similarity_search("", k=1000)  # ìµœëŒ€ 1000ê°œ ê°€ì ¸ì˜¤ê¸° (í•„ìš” ì‹œ ì¡°ì • ê°€ëŠ¥)

    # ğŸ” ê° ë¬¸ì„œì—ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    remarks = [doc.metadata for doc in all_docs]
    
    print(f"ğŸ”„ FAISSì—ì„œ {len(remarks)}ê°œì˜ ì”ì†Œë¦¬ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    pprint.pprint(remarks)
    return remarks

def replace_remark_in_faiss(original_remark: str, new_remark: str, updated_metadata: dict):
    """FAISSì—ì„œ ê¸°ì¡´ remarkë¥¼ ì°¾ì•„ ìƒˆë¡œìš´ remarkë¡œ ëŒ€ì²´"""
    all_documents = db.similarity_search(original_remark, k=10)  # ğŸ”¥ ìµœëŒ€ 10ê°œ ê²€ìƒ‰ í›„ ì°¾ê¸°

    for doc in all_documents:
        if doc.page_content == original_remark:
            # ğŸ”¥ 1ï¸âƒ£ ê¸°ì¡´ remark ì‚­ì œ
            db.delete([doc.id])

            # ğŸ”¥ 2ï¸âƒ£ ìƒˆë¡œìš´ remarkë¡œ êµì²´ (ê°™ì€ metadata ìœ ì§€)
            updated_metadata["remark"] = new_remark  # ğŸ”¥ ìƒˆë¡œìš´ remarkë¡œ êµì²´
            db.add_texts([new_remark], metadatas=[updated_metadata])

            # ğŸ”¥ 3ï¸âƒ£ ë³€ê²½ ì‚¬í•­ ì €ì¥
            db.save_local(index_path)
            print(f"âœ… FAISSì—ì„œ remark êµì²´ ì™„ë£Œ: {original_remark} â†’ {new_remark}")
            return

    print("âŒ ëŒ€ì²´í•  remarkë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")



# ì‹¤í–‰ ì‹œ FAISS ì¸ë±ìŠ¤ ë¡œë“œ
load_faiss_index()
